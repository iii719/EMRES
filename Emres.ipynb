{"cells":[{"cell_type":"markdown","source":["모델 설명\n","\n","사용자 프로필 : 각 사용자마다 좋아요/싫어요를 누른 데이터들이 존재\n","\n","아이템 카탈로그 : 아이템(음악)마다 contents vector와 emotion vector가 존재\n","\n","contents vector : <TF-IDF, low-level features, genres>\n","\n","emotion vector : 가사에 대한 emotion <score, magnitude>"],"metadata":{"id":"Lo1EHJg0cY1o"}},{"cell_type":"markdown","metadata":{"id":"jXZ50Ou1lzmI"},"source":["# settings"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24405,"status":"ok","timestamp":1691846957538,"user":{"displayName":"박요한","userId":"18078957727534871434"},"user_tz":-540},"id":"y26BG3adnA4q","outputId":"d709b2eb-9550-4610-e28c-d52a29e26c97"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1691846957539,"user":{"displayName":"박요한","userId":"18078957727534871434"},"user_tz":-540},"id":"gnuqN2MRLBaf","outputId":"90940072-8592-4488-c52a-c1bdc3bcfc97"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/EMRES\n"]}],"source":["cd \"/content/drive/MyDrive/EMRES\""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17370,"status":"ok","timestamp":1691846974906,"user":{"displayName":"박요한","userId":"18078957727534871434"},"user_tz":-540},"id":"uVk7s7Lhr_9N","outputId":"4be4bd43-ba6a-4ccc-8ee0-e87fce1f8959"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting tinytag\n","  Downloading tinytag-1.9.0.tar.gz (39 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting spotipy\n","  Downloading spotipy-2.23.0-py3-none-any.whl (29 kB)\n","Collecting jellyfish\n","  Downloading jellyfish-1.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pylast\n","  Downloading pylast-5.2.0-py3-none-any.whl (29 kB)\n","Collecting fake_useragent\n","  Downloading fake_useragent-1.2.1-py3-none-any.whl (14 kB)\n","Collecting redis>=3.5.3 (from spotipy)\n","  Downloading redis-4.6.0-py3-none-any.whl (241 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.1/241.1 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests>=2.25.0 in /usr/local/lib/python3.10/dist-packages (from spotipy) (2.31.0)\n","Requirement already satisfied: six>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spotipy) (1.16.0)\n","Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from spotipy) (2.0.4)\n","Collecting httpx (from pylast)\n","  Downloading httpx-0.24.1-py3-none-any.whl (75 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.4/75.4 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: async-timeout>=4.0.2 in /usr/local/lib/python3.10/dist-packages (from redis>=3.5.3->spotipy) (4.0.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.25.0->spotipy) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.25.0->spotipy) (3.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.25.0->spotipy) (2023.7.22)\n","Collecting httpcore<0.18.0,>=0.15.0 (from httpx->pylast)\n","  Downloading httpcore-0.17.3-py3-none-any.whl (74 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.5/74.5 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->pylast) (1.3.0)\n","Collecting h11<0.15,>=0.13 (from httpcore<0.18.0,>=0.15.0->httpx->pylast)\n","  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from httpcore<0.18.0,>=0.15.0->httpx->pylast) (3.7.1)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->httpcore<0.18.0,>=0.15.0->httpx->pylast) (1.1.2)\n","Building wheels for collected packages: tinytag\n","  Building wheel for tinytag (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for tinytag: filename=tinytag-1.9.0-py3-none-any.whl size=36820 sha256=a42a7a30d261927e6ac5aa18e508f06d2d3cda316e34f35112f36be608262df6\n","  Stored in directory: /root/.cache/pip/wheels/c5/30/dd/4838f2a4769fbe88d28f55035ed2f3f52be5e30ea76e4d656f\n","Successfully built tinytag\n","Installing collected packages: fake_useragent, tinytag, redis, jellyfish, h11, spotipy, httpcore, httpx, pylast\n","Successfully installed fake_useragent-1.2.1 h11-0.14.0 httpcore-0.17.3 httpx-0.24.1 jellyfish-1.0.0 pylast-5.2.0 redis-4.6.0 spotipy-2.23.0 tinytag-1.9.0\n"]}],"source":["!pip install tinytag spotipy jellyfish pylast fake_useragent"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8114,"status":"ok","timestamp":1691846983014,"user":{"displayName":"박요한","userId":"18078957727534871434"},"user_tz":-540},"id":"UHF5KmggMYjN","outputId":"78313fbe-1e0e-4bd0-8ca5-7147ff89dc05"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]}],"source":["import base64\n","import concurrent.futures\n","import json\n","import os\n","import pickle\n","import re\n","import requests\n","from bs4 import BeautifulSoup, Comment\n","from collections import defaultdict\n","from datetime import datetime\n","from google.cloud import language_v1\n","from google.colab import files\n","from google.oauth2 import service_account\n","from google.auth import exceptions\n","from googleapiclient.discovery import build\n","from googlesearch import search\n","import nltk\n","from nltk.corpus import stopwords\n","from nltk.stem import PorterStemmer\n","from nltk.tokenize import word_tokenize\n","from nltk.util import ngrams\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from tinytag import TinyTag\n","import pandas as pd\n","import spotipy\n","from spotipy.oauth2 import SpotifyClientCredentials\n","from concurrent.futures import ThreadPoolExecutor\n","from requests.adapters import HTTPAdapter\n","from requests.packages.urllib3.util.retry import Retry\n","from pylast import LastFMNetwork, Track\n","import pylast\n","import jellyfish\n","from sklearn.metrics.pairwise import cosine_similarity\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import numpy as np\n","import math\n","import random\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset,DataLoader\n","from sklearn.decomposition import PCA\n","import copy\n","from fake_useragent import UserAgent\n","\n","nltk.download('stopwords')\n","nltk.download('punkt')\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"]},{"cell_type":"markdown","metadata":{"id":"NHP4zfy-gyni"},"source":["사용할 데이터셋의 음악파일 경로 지정"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"R5Osdvzs4r69"},"outputs":[],"source":["music_path = \"emotifymusic_integrated\""]},{"cell_type":"markdown","metadata":{"id":"2t0JepgmlsR0"},"source":["# Item contents vectors + Item emotion vectors"]},{"cell_type":"markdown","metadata":{"id":"qg2uFMkqgTBB"},"source":["만들어야 할 딕셔너리 정리\n","\n","1. music_lyrics - 곡번호 : 가사\n","\n","    music_title - 곡번호 : 제목\n","  \n","2. music_spotify - 곡번호 : low_level_audio_features - (Item contents vectors)\n","\n","\n","3. music_TFIDF - 곡번호 : TF-IDF - (Item contents vectors)\n","\n","\n","4. music_genres - 곡번호 : 장르 - (Item contents vectors)\n","\n","\n","5. music_emotion - 곡번호 : 가사감정 - (Item emotion vectors)"]},{"cell_type":"markdown","metadata":{"id":"GDoiBmtot4GK"},"source":["1. music_lyrics - 곡번호 : 가사\n","\n","   music_title - 곡번호 : 제목\n","\n","    파일명과 가사를 매핑하기 위해 가사를 검색 후 사이트 별로 몇 개의 곡의 가사를 갖는지 조사(논문에서 사용한 사이트들로만 구성)"]},{"cell_type":"markdown","metadata":{"id":"kVxmAtWFopzy"},"source":["각 사이트마다 몇 개의 곡을 갖고 있는지 조사"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"YBaW6qn-W999"},"outputs":[],"source":["def count_search_results(song_title, filename):\n","    count_dict = defaultdict(list)\n","    #검색결과중 10개만 체크\n","    for url in search(song_title + \" lyrics\", stop=10):\n","        for lyrics_site in lyrics_sites:\n","            if lyrics_site in url:\n","                count_dict[lyrics_site].append(filename)\n","    return count_dict\n","\n","#논문에서 사용한 가사 사이트 전체\n","lyrics_sites = [\"azlyrics.com\", \"elyrics.net\", \"lyricsera.com\", \"sweetlyrics.com\",\n","                \"lyricsfreak.com\", \"songlyrics.com\", \"lyricsmode.com\", \"metrolyrics.com\",\n","                \"flashlyrics.com\", \"lololyrics.com\", \"songtexte.com\", \"lyricsmania.com\",\n","                \"songmeanings.com\", \"lyricsofsong.com\"]\n","\n","site_results = defaultdict(list)\n","\n","def process_file(filename):\n","    if filename.endswith(\".mp3\"):\n","        file_path = os.path.join(music_path, filename)\n","        tag = TinyTag.get(file_path)\n","        return count_search_results(tag.title, filename)\n","\n","#병렬처리를 위한 라이브러리 사용\n","with ThreadPoolExecutor(max_workers=10) as executor:\n","    results = list(executor.map(process_file, os.listdir(music_path)))\n","\n","for result in results:\n","    if result:\n","        for site, songs in result.items():\n","            site_results[site].extend(songs)\n","\n","# 구글에 노래 제목 검사 결과 해당 사이트들에서 어떤 곡이 나오는지\n","for site, songs in sorted(site_results.items(), key=lambda item: len(item[1]), reverse=True):\n","    print(f\"{site}: {len(songs)} songs\")"]},{"cell_type":"markdown","metadata":{"id":"qf2BddpSsek4"},"source":["중복되는 검색결과를 제외\n","\n","azlyrics.com, songlyrics.com, songtexte.com, songmeanings.com, flashlyrics.com에서만 조사"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"GVchMqCirpIm","outputId":"737f542f-0564-4963-ce7d-fe981663d169"},"outputs":[{"name":"stdout","output_type":"stream","text":["Minimum sites to cover all songs:\n","azlyrics.com: 159 new songs\n","songlyrics.com: 40 new songs\n","songtexte.com: 23 new songs\n","songmeanings.com: 10 new songs\n","flashlyrics.com: 6 new songs\n","lyricsmode.com: 2 new songs\n","lololyrics.com: 1 new songs\n"]}],"source":["def get_minimum_sites(site_results):\n","    all_songs = set(song for songs in site_results.values() for song in songs)\n","\n","    site_results_working = dict(site_results)\n","\n","    minimum_sites = []\n","\n","    found_songs = set()\n","\n","    while all_songs != found_songs:\n","        best_site = max(site_results_working, key=lambda x: len(set(site_results_working[x]) - found_songs))\n","\n","        new_songs = set(site_results_working[best_site]) - found_songs\n","\n","        found_songs |= new_songs\n","\n","        minimum_sites.append((best_site, len(new_songs)))\n","\n","        del site_results_working[best_site]\n","\n","    return minimum_sites\n","\n","minimum_sites = get_minimum_sites(site_results)\n","\n","for site, num_songs in minimum_sites:\n","    print(f\"{site}: {num_songs} new songs\")"]},{"cell_type":"markdown","metadata":{"id":"Lcw1J8YCozqn"},"source":["주요 5개의 사이트를 기준으로 가사를 매핑\n","\n","총 400곡중 79곡에 매핑:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lUsBQnu_vZnN"},"outputs":[],"source":["lyrics_sites = [\"azlyrics.com\", \"songlyrics.com\", \"songtexte.com\", \"songmeanings.com\", \"flashlyrics.com\"]\n","\n","session = requests.Session()\n","retry = Retry(total=5, backoff_factor=0.1, status_forcelist=[ 500, 502, 503, 504 ])\n","adapter = HTTPAdapter(max_retries=retry)\n","session.mount('http://', adapter)\n","session.mount('https://', adapter)\n","\n","def get_lyrics_from_site(soup, url):\n","  # 각 사이트에 직접 들어가서 가사에 해당하는 HTML 부분을 가져와서 비교\n","    if \"azlyrics.com\" in url:\n","        outer_div = soup.find('div', class_='col-xs-12 col-lg-8 text-center')\n","        if outer_div:\n","            lyrics_div = next((child for child in outer_div.children if child.name == 'div' and not child.has_attr('class')), None)\n","            if lyrics_div:\n","                return lyrics_div.get_text(separator=\"\\n\")\n","    elif \"songlyrics.com\" in url:\n","        lyrics_div = soup.find('p', {'id': 'songLyricsDiv'})\n","        if lyrics_div:\n","            return lyrics_div.text.strip()\n","    elif \"songtexte.com\" in url:\n","        lyrics_div = soup.find('div', {'id': 'lyrics'})\n","        if lyrics_div:\n","            return lyrics_div.text.strip()\n","    elif \"songmeanings.com\" in url:\n","        lyrics_div = soup.find('div', {'class': 'holder lyric-box'})\n","        if lyrics_div:\n","            return lyrics_div.text.strip()\n","    elif \"flashlyrics.com\" in url:\n","        lyrics_div = soup.find('div', {'class': 'main-panel-content'})\n","        if lyrics_div:\n","            return lyrics_div.text.strip()\n","    return None\n","\n","ua = UserAgent()\n","def get_lyrics(song_title, filename):\n","    for url in search(song_title + \" lyrics\", stop=10):\n","        if any(lyrics_site in url for lyrics_site in lyrics_sites):\n","            headers = {'User-Agent': ua.random}\n","            print(f\"{url}에 {song_title}가사가 있습니다\")\n","            response = session.get(url, headers=headers, timeout=10)\n","            soup = BeautifulSoup(response.text, 'html.parser')\n","\n","            lyrics = get_lyrics_from_site(soup, url)\n","            # 30글자 이하면 가사가 없다는 글이므로 제외\n","            if lyrics and len(lyrics) >= 30:\n","                return lyrics\n","    return None\n","\n","music_path = \"emotifymusic_integrated\"\n","music_lyrics = {}\n","music_title = {}\n","\n","def process_file(filename):\n","    if filename.endswith(\".mp3\"):\n","        file_path = os.path.join(music_path, filename)\n","        tag = TinyTag.get(file_path)\n","        lyrics = get_lyrics(tag.title, filename)\n","        if lyrics is None:\n","            print(f\"No lyrics: {filename}, Track Name: {tag.title}\")\n","        else:\n","            filename = os.path.splitext(filename)[0]\n","            music_lyrics[filename] = lyrics\n","            music_title[filename] = tag.title\n","\n","with concurrent.futures.ThreadPoolExecutor() as executor:\n","    list(executor.map(process_file, os.listdir(music_path)))"]},{"cell_type":"markdown","metadata":{"id":"7tn2loGi4ZqL"},"source":["키를 int,오름차순으로 바꿈"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7pyi1ZU63-rn"},"outputs":[],"source":["music_lyrics = {int(k): v for k, v in sorted(music_lyrics.items(), key=lambda item: int(item[0]))}\n","music_title = {int(k): v for k, v in sorted(music_title.items(), key=lambda item: int(item[0]))}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Gx-bXonw2pZ4"},"outputs":[],"source":["# with open('music_lyrics.pkl', 'wb') as f:\n","#     pickle.dump(music_lyrics, f)\n","# with open('music_title.pkl', 'wb') as f:\n","#     pickle.dump(music_title, f)\n","\n","with open('music_lyrics.pkl', 'rb') as f:\n","    music_lyrics = pickle.load(f)\n","with open('music_title.pkl', 'rb') as f:\n","    music_title = pickle.load(f)"]},{"cell_type":"markdown","metadata":{"id":"KQK05O5IasIK"},"source":["keys_using은 사용될 곡의 번호를 저장한 리스트(모든 정보들이 있는 곡들만 사용하기 위함)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EdFYHxdK788V","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1691847428803,"user_tz":-540,"elapsed":5,"user":{"displayName":"박요한","userId":"18078957727534871434"}},"outputId":"c6942f83-c979-482a-9769-0855ca3f8375"},"outputs":[{"output_type":"stream","name":"stdout","text":["122\n"]}],"source":["keys_using = list(music_lyrics.keys())\n","print(len(keys_using)) #122곡"]},{"cell_type":"markdown","metadata":{"id":"_ws9mXpzbFim"},"source":["2. music_spotify - 곡번호 : low_level_audio_features\n","\n","    spotify API를 이용"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"V2tFaKYzbFYG"},"outputs":[],"source":["client_id = '8e42f5c735c5482fb913c2573c49a751'\n","client_secret = '3be310f512ba40df8b456e2a5f346a58'\n","\n","client_credentials_manager = SpotifyClientCredentials(client_id=client_id, client_secret=client_secret)\n","sp = spotipy.Spotify(client_credentials_manager=client_credentials_manager)\n","\n","unsorted_music_spotify = {}\n","\n","def fetch_spotify_features(key):\n","    file = str(key) + \".mp3\"\n","    tag = TinyTag.get(os.path.join(music_path, file))\n","    title = tag.title\n","    artist = tag.artist\n","    result = sp.search(q=f'artist:{artist} track:{title}', type='track')\n","    if result['tracks']['items']:\n","        track_id = result['tracks']['items'][0]['id']\n","        features = sp.audio_features(track_id)\n","        return key, features\n","    else:\n","        print(f\"결과 없음 {title} - {artist}\")\n","        return key, None\n","\n","keys_to_remove = []\n","with ThreadPoolExecutor() as executor:\n","    futures = {executor.submit(fetch_spotify_features, key) for key in keys_using}\n","    for future in concurrent.futures.as_completed(futures):\n","        key, features = future.result()\n","        if features is not None:\n","            unsorted_music_spotify[int(key)] = features\n","\n","keys_using = list(unsorted_music_spotify.keys())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZJElSorUtA1k"},"outputs":[],"source":["#논문에서 사용한 10가지 특징만 사용\n","features = ['acousticness', 'danceability', 'energy', 'instrumentalness', 'key', 'liveness', 'loudness', 'mode', 'speechiness', 'tempo']\n","\n","music_spotify = {}\n","\n","for key in sorted(unsorted_music_spotify.keys()):\n","    value = unsorted_music_spotify[key][0]\n","    feature_values = {feature: value[feature] for feature in features}\n","    music_spotify[key] = list(feature_values.values())\n","\n","for key, value in music_spotify.items():\n","    print(f\"곡 번호: {key}, 특징 벡터: {value}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wFw5dEKOHwaO"},"outputs":[],"source":["with open('music_spotify.pkl', 'wb') as f:\n","    pickle.dump(music_spotify, f)\n","with open('music_spotify.pkl', 'rb') as f:\n","    music_spotify = pickle.load(f)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":504,"status":"ok","timestamp":1691849299610,"user":{"displayName":"박요한","userId":"18078957727534871434"},"user_tz":-540},"id":"dI35tUGhdiWH","outputId":"63f23af5-0c73-458f-d897-8cee15f2ec77"},"outputs":[{"output_type":"stream","name":"stdout","text":["104\n"]}],"source":["keys_using  = list(music_spotify.keys())\n","print(len(keys_using)) #122곡->104곡"]},{"cell_type":"markdown","metadata":{"id":"cGYtbYux37iw"},"source":["3. music_TFIDF - 곡번호 : TF-IDF\n","\n","    벡터간 유사도를 계산해야 하므로 같은 크기의 벡터로 만들기 위해 모든 가사의 나오는 단어를 고려하고 없다면 0점"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"erYsaHmG3-L5"},"outputs":[],"source":["#논문에서 사용한 텍스트 전처리\n","def preprocess_text(text):\n","    text = text.lower()\n","    text = re.sub(r'\\W', ' ', text)\n","    stop_words = set(stopwords.words('english'))\n","    tokens = word_tokenize(text)\n","    stemmer = PorterStemmer()\n","    tokens = [stemmer.stem(token) for token in tokens if token not in stop_words]\n","    bigrams = list(ngrams(tokens, 2))\n","    bigrams = [' '.join(bigram) for bigram in bigrams]\n","    return ' '.join(tokens + bigrams)\n","\n","keys_using_lyrics = [(key, music_lyrics[key]) for key in keys_using]\n","keys, processed_lyrics = zip(*[(key, preprocess_text(lyric)) for key, lyric in keys_using_lyrics])\n","\n","vectorizer = TfidfVectorizer()\n","tfidf_scores = vectorizer.fit_transform(processed_lyrics)\n","tfidf_matrix = tfidf_scores.toarray()\n","\n","#단어들이 합쳐지면 길이가 천이 넘는 큰 벡터가 되므로 계산의 용이성을 위해 99%의 정보를 갖는 벡터로 PCA\n","pca = PCA(n_components=0.99)\n","reduced_tfidf = pca.fit_transform(tfidf_matrix)\n","\n","music_TFIDF = {key: reduced_value for key, reduced_value in zip(keys, reduced_tfidf)}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KE7eBkOcm0d0"},"outputs":[],"source":["with open('music_TFIDF.pkl', 'wb') as f:\n","    pickle.dump(music_TFIDF, f)\n","with open('music_TFIDF.pkl', 'rb') as f:\n","    music_TFIDF = pickle.load(f)"]},{"cell_type":"markdown","metadata":{"id":"SfWxpAQI3v-z"},"source":["4. music_genres - 곡번호 : 장르(선택1)\n","\n","    last.fm API - 장르 정보를 추출\n","\n","    (이 부분을 빼고 meta data의 장르로 가져오면 노래 개수가 크게 늘어나는 효과가 있긴 함)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1nQFWVOK30ib"},"outputs":[],"source":["# API_KEY = '2159ccbcdc620d729aacd93c34985a1c'\n","# API_SECRET = '75606bca652d5c8407f7dca26a4f9b5f'\n","\n","network = pylast.LastFMNetwork(api_key=API_KEY, api_secret=API_SECRET)\n","# 논문에서 사용한 장르\n","Allmusic = set(['alternative', 'blues', 'classical', 'country', 'electronic', 'folk', 'jazz',\n","                'latin', 'new age', 'pop', 'rock', 'rap', 'r&b', 'reggae', 'stage & screen', 'vocal', 'world'])\n","def get_genres(filename):\n","    track_path = os.path.join(music_path, filename)\n","    track_id = os.path.splitext(filename)[0]\n","    artist = title = tag_genre = None\n","\n","    try:\n","        tag = TinyTag.get(track_path)\n","        title = tag.title\n","        artist = tag.artist\n","        tag_genre = tag.genre.lower() if tag.genre else None\n","    except Exception as e:\n","        print(f\"{track_id}의 정보 가져오기 실패: {e}\")\n","        return None, None\n","\n","    genre_encoding = [int(tag_genre == am_genre.lower()) for am_genre in Allmusic]\n","\n","    try:\n","        track = network.get_track(artist, title)\n","        top_tags = track.get_top_tags(limit=None)\n","        if top_tags:\n","            genres = set(tag.item.get_name().lower() for tag in top_tags)\n","            genre_encoding_from_tags = [int(am_genre.lower() in genres) for am_genre in Allmusic]\n","            genre_encoding = [max(x, y) for x, y in zip(genre_encoding, genre_encoding_from_tags)]\n","    except Exception as e:\n","        print(f\"실패 {track_id}: {e}\")\n","\n","    if not any(genre_encoding):\n","        print(f\"{track_id}는 속하는 장르가 없음.\")\n","        return None, None\n","\n","    return int(track_id), genre_encoding\n","\n","filenames = [f\"{str(key)}.mp3\" for key in keys_using]\n","\n","with concurrent.futures.ThreadPoolExecutor() as executor:\n","    results = executor.map(get_genres, filenames)\n","    music_genres = {key: genre for key, genre in results if key is not None}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wPuYavwIgNG-"},"outputs":[],"source":["# with open('music_genres.pkl', 'wb') as f:\n","#     pickle.dump(music_genres, f)\n","with open('music_genres.pkl', 'rb') as f:\n","    music_genres = pickle.load(f)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":511,"status":"ok","timestamp":1691847755867,"user":{"displayName":"박요한","userId":"18078957727534871434"},"user_tz":-540},"id":"KSp5Brr-dqIC","outputId":"f2f83a3a-0afe-4a00-f09c-2710b3935d86"},"outputs":[{"output_type":"stream","name":"stdout","text":["[68, 103, 109, 112, 130, 136, 143, 147, 157, 219, 238, 254, 303, 304, 307, 309, 313, 321, 323, 326, 333, 335, 336, 338, 340, 347, 350, 352, 356, 357, 367, 375, 376, 377, 378, 381, 384, 388, 389, 392, 395]\n","41\n"]}],"source":["# keys_using = list(music_genres.keys())\n","# print(keys_using)\n","# print(len(keys_using)) #122->41"]},{"cell_type":"markdown","source":["4. music_genres - 곡번호 : 장르(선택2)\n","\n","    메타데이터에서 장르데이터를 가져와 벡터로 사용\n"],"metadata":{"id":"QWNn-QSoDIhA"}},{"cell_type":"code","source":["unique_genres = set()\n","\n","# 첫 번째 단계: 모든 파일의 장르를 수집\n","filenames = [f\"{str(key)}.mp3\" for key in keys_using]\n","for filename in filenames:\n","    track_path = os.path.join(music_path, filename)\n","\n","    try:\n","        tag = TinyTag.get(track_path)\n","        if tag.genre:\n","            unique_genres.add(tag.genre.lower())\n","    except Exception as e:\n","        print(f\"Failed to get genre from track {filename}: {e}\")\n","\n","unique_genres = sorted(list(unique_genres))\n","\n","def get_genres(filename):\n","    track_path = os.path.join(music_path, filename)\n","    track_id = os.path.splitext(filename)[0]\n","\n","    try:\n","        tag = TinyTag.get(track_path)\n","        tag_genre = tag.genre.lower() if tag.genre else None\n","    except Exception as e:\n","        print(f\"{track_id}의 정보 가져오기 실패: {e}\")\n","        return None, None\n","\n","    genre_encoding = [float(tag_genre == genre) for genre in unique_genres]\n","\n","    if not any(genre_encoding):\n","        print(f\"{track_id}는 속하는 장르가 없음.\")\n","        return None, None\n","\n","    return int(track_id), genre_encoding\n","\n","music_genres = {}\n","for filename in filenames:\n","    key, genre = get_genres(filename)\n","    if key is not None:\n","        music_genres[key] = genre"],"metadata":{"id":"PGSTLI0BDG2m"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# with open('music_genres.pkl', 'wb') as f:\n","#     pickle.dump(music_genres, f)\n","with open('music_genres.pkl', 'rb') as f:\n","    music_genres = pickle.load(f)"],"metadata":{"id":"uJVAGY6rFIpD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["keys_using = list(music_genres.keys())\n","print(len(keys_using)) #122->104"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lmdxCRZJEurd","executionInfo":{"status":"ok","timestamp":1691849343579,"user_tz":-540,"elapsed":2,"user":{"displayName":"박요한","userId":"18078957727534871434"}},"outputId":"94ed92c5-28b5-4347-e48f-37fbe713243d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["104\n"]}]},{"cell_type":"markdown","metadata":{"id":"6fEgECluJqT4"},"source":["5. music_emotion - 곡번호 : 가사감정\n","\n","    google natural language cloud api로 가사 감정 분석\n","    \n","    감정을 score와 magnitude의 2차원으로 표현"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JQGvCFgrebdW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1691849398359,"user_tz":-540,"elapsed":15668,"user":{"displayName":"박요한","userId":"18078957727534871434"}},"outputId":"840af956-b08b-4fc7-c20b-4339b287e0cc"},"outputs":[{"output_type":"stream","name":"stdout","text":["Song: 109 | Sentiment Score: 0.1, Sentiment Magnitude: 1.7\n","Song: 121 | Sentiment Score: 0.2, Sentiment Magnitude: 5\n","Song: 119 | Sentiment Score: 0.3, Sentiment Magnitude: 2.7\n","Song: 106 | Sentiment Score: -0.5, Sentiment Magnitude: 8.3\n","Song: 108 | Sentiment Score: 0.1, Sentiment Magnitude: 6.6\n","Song: 103 | Sentiment Score: -0.4, Sentiment Magnitude: 6.3\n","Song: 112 | Sentiment Score: 0.3, Sentiment Magnitude: 3.7\n","Song: 132 | Sentiment Score: 0.6, Sentiment Magnitude: 12.8\n","Song: 130 | Sentiment Score: -0.3, Sentiment Magnitude: 8.3\n","Song: 146 | Sentiment Score: -0.6, Sentiment Magnitude: 6.2\n","Song: 136 | Sentiment Score: -0.2, Sentiment Magnitude: 1\n","Song: 142 | Sentiment Score: -0.2, Sentiment Magnitude: 0.4\n","Song: 139 | Sentiment Score: -0.4, Sentiment Magnitude: 3.3\n","Song: 147 | Sentiment Score: 0.3, Sentiment Magnitude: 2.6\n","Song: 145 | Sentiment Score: 0.5, Sentiment Magnitude: 3.7\n","Song: 155 | Sentiment Score: 0.2, Sentiment Magnitude: 7.3\n","Song: 152 | Sentiment Score: -0.8, Sentiment Magnitude: 0.8\n","Song: 157 | Sentiment Score: -0.6, Sentiment Magnitude: 7.1\n","Song: 143 | Sentiment Score: -0.6, Sentiment Magnitude: 6.7\n","Song: 163 | Sentiment Score: -0.2, Sentiment Magnitude: 5.3\n","Song: 166 | Sentiment Score: -0.2, Sentiment Magnitude: 5.3\n","Song: 170 | Sentiment Score: 0.4, Sentiment Magnitude: 8.7\n","Song: 188 | Sentiment Score: 0.3, Sentiment Magnitude: 3.1\n","Song: 172 | Sentiment Score: -0.4, Sentiment Magnitude: 5.4\n","Song: 175 | Sentiment Score: -0.4, Sentiment Magnitude: 5.4\n","Song: 176 | Sentiment Score: 0.4, Sentiment Magnitude: 8.7\n","Song: 182 | Sentiment Score: 0.2, Sentiment Magnitude: 3\n","Song: 181 | Sentiment Score: -0.3, Sentiment Magnitude: 12.8\n","Song: 189 | Sentiment Score: -0.4, Sentiment Magnitude: 5.9\n","Song: 192 | Sentiment Score: -0.6, Sentiment Magnitude: 0.6\n","Song: 209 | Sentiment Score: -0.3, Sentiment Magnitude: 5.1\n","Song: 196 | Sentiment Score: -0.5, Sentiment Magnitude: 2.8\n","Song: 225 | Sentiment Score: 0.4, Sentiment Magnitude: 0.4\n","Song: 216 | Sentiment Score: 0.5, Sentiment Magnitude: 3.3\n","Song: 227 | Sentiment Score: 0.4, Sentiment Magnitude: 4\n","Song: 198 | Sentiment Score: -0.1, Sentiment Magnitude: 8.7\n","Song: 250 | Sentiment Score: 0.5, Sentiment Magnitude: 1.6\n","Song: 232 | Sentiment Score: -0.6, Sentiment Magnitude: 5\n","Song: 231 | Sentiment Score: -0.3, Sentiment Magnitude: 2.9\n","Song: 233 | Sentiment Score: -0.1, Sentiment Magnitude: 2.7\n","Song: 235 | Sentiment Score: 0.4, Sentiment Magnitude: 2.6\n","Song: 239 | Sentiment Score: -0.1, Sentiment Magnitude: 5.3\n","Song: 238 | Sentiment Score: -0.2, Sentiment Magnitude: 3.3\n","Song: 251 | Sentiment Score: -0.1, Sentiment Magnitude: 12.8\n","Song: 254 | Sentiment Score: -0.1, Sentiment Magnitude: 1.8\n","Song: 259 | Sentiment Score: 0.4, Sentiment Magnitude: 6.8\n","Song: 266 | Sentiment Score: 0.4, Sentiment Magnitude: 6.8\n","Song: 271 | Sentiment Score: -0.3, Sentiment Magnitude: 12\n","Song: 270 | Sentiment Score: -0.4, Sentiment Magnitude: 3.6\n","Song: 281 | Sentiment Score: 0.1, Sentiment Magnitude: 5.4\n","Song: 284 | Sentiment Score: -0.5, Sentiment Magnitude: 5.3\n","Song: 275 | Sentiment Score: -0.1, Sentiment Magnitude: 6.9\n","Song: 290 | Sentiment Score: 0.1, Sentiment Magnitude: 0.6\n","Song: 294 | Sentiment Score: -0.5, Sentiment Magnitude: 5.1\n","Song: 297 | Sentiment Score: -0.5, Sentiment Magnitude: 4.4\n","Song: 323 | Sentiment Score: -0.5, Sentiment Magnitude: 3.9\n","Song: 304 | Sentiment Score: -0.6, Sentiment Magnitude: 5.3\n","Song: 309 | Sentiment Score: -0.5, Sentiment Magnitude: 3.2\n","Song: 307 | Sentiment Score: -0.2, Sentiment Magnitude: 2.9\n","Song: 335 | Sentiment Score: 0.5, Sentiment Magnitude: 2.9\n","Song: 321 | Sentiment Score: 0.1, Sentiment Magnitude: 9.8\n","Song: 338 | Sentiment Score: -0.5, Sentiment Magnitude: 5.3\n","Song: 313 | Sentiment Score: 0.2, Sentiment Magnitude: 4.8\n","Song: 336 | Sentiment Score: -0.4, Sentiment Magnitude: 1.8\n","Song: 326 | Sentiment Score: -0.2, Sentiment Magnitude: 3.4\n","Song: 333 | Sentiment Score: -0.2, Sentiment Magnitude: 1.6\n","Song: 340 | Sentiment Score: -0.7, Sentiment Magnitude: 0.7\n","Song: 347 | Sentiment Score: 0.3, Sentiment Magnitude: 3\n","Song: 350 | Sentiment Score: -0.3, Sentiment Magnitude: 3.2\n","Song: 376 | Sentiment Score: -0.4, Sentiment Magnitude: 3.7\n","Song: 357 | Sentiment Score: 0.1, Sentiment Magnitude: 4.1\n","Song: 356 | Sentiment Score: -0.4, Sentiment Magnitude: 5.8\n","Song: 377 | Sentiment Score: 0.5, Sentiment Magnitude: 5.7\n","Song: 370 | Sentiment Score: -0.1, Sentiment Magnitude: 4.3\n","Song: 375 | Sentiment Score: -0.3, Sentiment Magnitude: 2\n","Song: 367 | Sentiment Score: -0.7, Sentiment Magnitude: 8.6\n","Song: 388 | Sentiment Score: -0.1, Sentiment Magnitude: 5.1\n","Song: 381 | Sentiment Score: 0.2, Sentiment Magnitude: 2.9\n","Song: 389 | Sentiment Score: -0.1, Sentiment Magnitude: 3.2\n","Song: 392 | Sentiment Score: -0.1, Sentiment Magnitude: 3.9\n"]}],"source":["api_key = 'AIzaSyAn2RVMM0SEWyLXjMWc0y_-gWysSGO2jSY'\n","url = f'https://language.googleapis.com/v1/documents:analyzeSentiment?key={api_key}'\n","headers = {'Content-Type': 'application/json'}\n","\n","def analyze_lyrics_sentiment(key):\n","    lyrics = music_lyrics[key]\n","    body = {\n","        \"document\": {\n","            \"type\": \"PLAIN_TEXT\",\n","            \"language\": \"EN\",\n","            \"content\": lyrics\n","        },\n","        \"encodingType\": \"UTF8\"\n","    }\n","\n","    response = requests.post(url, headers=headers, json=body)\n","    if response.status_code == 200:\n","        sentiment = response.json()['documentSentiment']\n","        return key, sentiment['score'], sentiment['magnitude']\n","    else:\n","        return key, None, None\n","\n","def process_results():\n","    with ThreadPoolExecutor(max_workers=10) as executor:\n","        futures = [executor.submit(analyze_lyrics_sentiment, key) for key in keys_using]\n","        music_emotion = {key: (score, magnitude) for key, score, magnitude in (future.result() for future in concurrent.futures.as_completed(futures)) if score and magnitude}\n","\n","    for key, value in music_emotion.items():\n","        print(f\"Song: {key} | Sentiment Score: {value[0]}, Sentiment Magnitude: {value[1]}\")\n","    return music_emotion\n","\n","music_emotion = process_results()"]},{"cell_type":"code","source":["keys_using = list(music_emotion.keys())\n","print(len(keys_using))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"319R7Zuy_qtK","executionInfo":{"status":"ok","timestamp":1691849403175,"user_tz":-540,"elapsed":510,"user":{"displayName":"박요한","userId":"18078957727534871434"}},"outputId":"674ff6fe-7328-45d5-f830-c4d782892a94"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["80\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bf-3Cn5Ed-0N"},"outputs":[],"source":["with open('music_emotion.pkl', 'wb') as f:\n","    pickle.dump(music_emotion, f)\n","with open('music_emotion.pkl', 'rb') as f:\n","    music_emotion = pickle.load(f)"]},{"cell_type":"markdown","metadata":{"id":"HTjTBQrdntDa"},"source":["딕셔너리 점검\n","\n","1. music_lyrics - 곡번호 : 가사\n","\n","    music_title - 곡번호 : 제목\n","  \n","2. music_spotify - 곡번호 : low_level_audio_features\n","\n","\n","3. music_TFIDF - 곡번호 : TF-IDF\n","\n","\n","4. music_genres - 곡번호 : 장르\n","\n","\n","5. music_emotion - 곡번호 : 가사감정"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pSjsgzs2nkvp"},"outputs":[],"source":["dict_mapping = {\n","    \"music_spotify\": music_spotify,\n","    \"music_TFIDF\": music_TFIDF,\n","    \"music_genres\": music_genres,\n","    \"music_emotion\": music_emotion\n","}\n","\n","for dict_name, d in dict_mapping.items():\n","    print(dict_name)\n","    keys = list(d.keys())\n","    print(\"Key type:\", type(keys[0]))\n","    print(\"곡의 개수\", len(keys))\n","\n","    first_key = keys[0]\n","    first_value = d[first_key]\n","    print(\"Value type:\", type(first_value))\n","\n","    print(\"모든 값은 같은 길이\" if all(len(value) == len(first_value) for value in d.values()) else \"값에 다른 길이가 존재\")\n","    print()"]},{"cell_type":"markdown","metadata":{"id":"wBu9QczzmUdo"},"source":["item contents vectors"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gMH3-06eZUG7"},"outputs":[],"source":["music_vectors = {key: music_TFIDF[key].tolist() + music_spotify[key] + music_genres[key] for key in keys_using}"]},{"cell_type":"markdown","metadata":{"id":"A1XMZSOFpm8q"},"source":["# 데이터셋 로드\n","\n","user_info가 동일한 사람들을 같은 사람들로 보고 프로필 형성(' age', ' gender', ' mother tongue')\n","\n","사용자당 데이터의 개수가 부족하기 떄문\n","\n","(논문에선 사용자당 평균 데이터가 4.67개지만 사용한 데이터셋에선 알 수 없음)\n","\n","논문에서 노래는 509곡, 이 데이터셋에선 100곡 이하\n","\n","사용자의 affective state가 논문에선 6-감정이었지만, 이 데이터셋에선 1~5의 정수\n","(이 부분이 가장 큰 정확도 차이 유발)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ietki3aVt2tR"},"outputs":[],"source":["data = pd.read_csv('data.csv')\n","data_pref = data[(data['track id'].isin(keys_using)) & (data[' liked'] != data[' disliked'])]\n","data_liked = data_pref[data_pref[' liked'] == 1]\n","\n","datasets = {\n","    'pref': data_pref, #pref는 싫어요 표시도 이용한다면 사용할 수 있는 데이터셋\n","    'liked': data_liked,\n","}\n","\n","def process_data(profile_name, data):\n","    profile_dict = build_user_profile(data)\n","    remove_duplicates_and_sort(profile_dict)\n","\n","    return profile_dict\n","\n","def build_user_profile(data):\n","    user_id = 1\n","    profile_dict = {}\n","\n","    for group_info, group in data.groupby([' age', ' gender', ' mother tongue']):\n","        group_data = list(group[['track id', ' liked', ' mood']].itertuples(index=False))\n","        if len(group_data) > 1:\n","            profile_dict[user_id] = [track_info[:3] for track_info in group_data]\n","            user_id += 1\n","\n","    return profile_dict\n","\n","def remove_duplicates_and_sort(profile_dict):\n","    for key, value_list in profile_dict.items():\n","        first_elements = {tup[0]: tup for tup in sorted(value_list, key=lambda x: x[1], reverse=True)}\n","        profile_dict[key] = list(first_elements.values())\n","\n","def print_user_stats(user_dataset):\n","    for key, dataset in user_dataset.items():\n","        print(key)\n","\n","        length_counts = defaultdict(int)\n","        total_users = 0\n","        total_data = 0\n","        for value in dataset.values():\n","            length_counts[len(value)] += 1\n","            total_users += 1\n","            total_data += len(value)\n","\n","        for k, v in sorted(length_counts.items()):\n","            print(f'  데이터가 {k}개인 유저는 {v}명')\n","\n","        print(f'  총 데이터 수: {total_data}')\n","        print(f'  총 사용자 수: {total_users}')\n","        print()\n","\n","user_dataset = {key: process_data(key, data) for key, data in datasets.items()}\n","print_user_stats(user_dataset)"]},{"cell_type":"code","source":["for k,v in user_dataset['liked'].items():\n","  print(f'사용자 {k}의 데이터: {v}')"],"metadata":{"id":"Cu0EsoyVH3Qf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OistsBwIgDrT"},"source":["# EMRES RecSys - 논문 기반"]},{"cell_type":"markdown","metadata":{"id":"KNByjIn3Ig_O"},"source":["사용자 데이터 : (track id, liked, mood)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wh1zqx2lgW8P"},"outputs":[],"source":["class EMRES:\n","    def __init__(self, hyperparams, music_emotion, music_vectors):\n","        self.k = hyperparams['k']\n","        self.n = hyperparams['n']\n","        self.alpha = hyperparams['alpha']\n","        self.beta = hyperparams['beta']\n","        self.music_emotion = music_emotion\n","        self.music_vectors = music_vectors\n","\n","    def get_similarities(self, emotion_vector, songs, song_to_exclude):\n","        return [cosine_similarity([emotion_vector], [self.music_emotion[i]]) for i in songs if i != song_to_exclude]\n","\n","    def test(self, user_dataset):\n","        total_data = 0\n","        total_hits = 0\n","\n","        for user, user_data in user_dataset['liked'].items():\n","            if len(user_data) <= 1:\n","                continue\n","            train_data = user_data[:int(len(user_data) * 0.7)]\n","            test_data = user_data[int(len(user_data) * 0.7):]\n","            train_likes = [t for t in train_data if t[1] == 1]\n","            train_dislikes = [t for t in train_data if t[1] == 0]\n","\n","            for song, rating, emotion in test_data:\n","                likes = min(train_likes, key=lambda x: abs(x[2] - emotion), default=None)\n","                if likes is None:\n","                    continue\n","                total_data += 1\n","                dislikes = min(train_dislikes, key=lambda x: abs(x[2] - emotion), default=None)\n","\n","                top_k_songs = []\n","                #pref를 사용한다면 아래처럼 싫어요를 이용할 수 있음\n","                if dislikes:\n","                    dislikes_similarities = self.get_similarities(music_emotion[dislikes[0]], keys_using, song)\n","                    top_k_songs = [song for _, song in sorted(zip(dislikes_similarities, keys_using), reverse=True)][:self.k]\n","\n","                remaining_songs = [i for i in keys_using if i not in top_k_songs]\n","\n","                likes_similarities = self.get_similarities(music_emotion[likes[0]], remaining_songs, None)\n","                audio_features = [cosine_similarity([music_vectors[likes[0]]], [music_vectors[i]]) for i in remaining_songs]\n","\n","                aff_rec_score = [self.alpha * likes_sim + self.beta * audio_feat for likes_sim, audio_feat in zip(likes_similarities, audio_features)]\n","                sorted_songs_with_similarities = [song for score, song in sorted(zip(aff_rec_score, remaining_songs), reverse=True)][:self.n]\n","\n","                if song in sorted_songs_with_similarities:\n","                    total_hits += 1\n","\n","        hit_at_n = total_hits / total_data\n","        print(f'HIT@n: {hit_at_n:.4f}')\n","        return hit_at_n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GQnanRD51Ey1"},"outputs":[],"source":["def run_test(hyperparams, n_values, music_emotion, music_vectors):\n","    best_alpha = 0\n","    best_beta = 0\n","    best_hit_at_n = 0\n","\n","    for alpha_value in range(0, 11):\n","        alpha = alpha_value / 10\n","        beta = 1 - alpha\n","        hyperparams['alpha'] = alpha\n","        hyperparams['beta'] = beta\n","        print(f\"alpha: {alpha:.1f}, beta: {beta:.1f}\")\n","        emres = EMRES(hyperparams, music_emotion, music_vectors)\n","        hit_at_n = emres.test(user_dataset)\n","\n","        if hit_at_n > best_hit_at_n:\n","            best_hit_at_n = hit_at_n\n","            best_alpha = alpha\n","            best_beta = beta\n","\n","    print(f\"best alpha: {best_alpha:.1f}, beta: {best_beta:.1f}\")\n","    print()\n","\n","    hyperparams['alpha'] = best_alpha\n","    hyperparams['beta'] = best_beta\n","\n","    for n_value in n_values:\n","        hyperparams['n'] = n_value\n","        n_percentage = n_value / len(keys_using) * 100\n","        print(f\"n: {n_value}, 전체 노래의 {n_percentage:.2f}%\")\n","        emres = EMRES(hyperparams, music_emotion, music_vectors)\n","        emres.test(user_dataset)\n","        print()\n","\n","hyperparams = {\n","    'k': 5,\n","    'n': 16,\n","    'alpha': 0,\n","    'beta': 0\n","}\n","\n","n_values = range(14, 19,2)\n","run_test(hyperparams, n_values, music_emotion, music_vectors)"]},{"cell_type":"markdown","metadata":{"id":"mYtdmGzdj6hJ"},"source":["# 딥러닝 추가"]},{"cell_type":"markdown","metadata":{"id":"jftPsAtIFIRB"},"source":["데이터셋 섞어서 분할"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pBMckTGKFIDo"},"outputs":[],"source":["def random_split_user_data(user_data, test_size=1):\n","    random.shuffle(user_data)\n","    test_data = user_data[:test_size]\n","    train_data = user_data[test_size:]\n","    return train_data, test_data\n","\n","def split_users_into_train_test(user_dataset, test_size=1):\n","    new_user_profile_train = defaultdict(list)\n","    new_user_profile_test = defaultdict(list)\n","    user_id = max(user_dataset.keys()) + 1\n","\n","    for key, user_data in user_dataset.items():\n","        train_data, test_data = random_split_user_data(user_data, test_size)\n","        data_length = len(train_data)\n","\n","        if data_length == 1:\n","            continue\n","        else:\n","            new_user_profile_train[user_id] = train_data\n","            new_user_profile_test[user_id] = test_data\n","            user_id += 1\n","\n","    return new_user_profile_train, new_user_profile_test"]},{"cell_type":"markdown","source":["알파, 베타, 감마를 가중치로 두고 딥러닝"],"metadata":{"id":"CarAg884Z_QX"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"pGHxumK0j8pE"},"outputs":[],"source":["class ScoringModel(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.weights = nn.Parameter(torch.ones(3, 1))\n","\n","    def forward(self, user_emotion_sim, music_emotion_sim, audio_features_sim):\n","        user_score = user_emotion_sim * self.weights[0]\n","        music_score = music_emotion_sim * self.weights[1]\n","        audio_score = audio_features_sim * self.weights[2]\n","\n","        total_score = user_score + music_score + audio_score\n","        sorted_songs_with_scores = [(song, score) for song, score in sorted(zip(keys_using, total_score), key=lambda x: x[1], reverse=True)]\n","\n","        return sorted_songs_with_scores\n","\n","    def get_weights(self):\n","        return self.weights\n","\n","def custom_loss(sorted_scores, true_score, n):\n","    n_score = sorted_scores[n-1][1]\n","    n_plus_one_score = sorted_scores[n][1]\n","    #불연속 함수를 사용할땐 미분이 안되니까 학습안됨 ReLU는 max(0,x)를 쓰긴하지만 미분가능하게 조절이 되어있음\n","    loss1 = torch.relu(n_plus_one_score - true_score)  # n+1등과의 마진\n","    loss2 = 0\n","    hit = 0\n","    if loss1==0:\n","        loss2 = torch.relu(true_score - n_score)  # n등과의 마진\n","        hit+=1\n","\n","    return loss1+loss2, hit\n","\n","def calculate_similarity(emotion, likes, keys_using, music_emotion, music_vectors):\n","    u_emotion_sim = 1 / (abs(emotion - likes[2]) + 1)\n","    user_emotion_sim = torch.full((len(keys_using),), u_emotion_sim, dtype=torch.float32)\n","    music_emotion_sim = torch.tensor(cosine_similarity([music_emotion[likes[0]]], [music_emotion[i] for i in keys_using]), dtype=torch.float32).squeeze()\n","    audio_features_sim = torch.tensor(cosine_similarity([music_vectors[likes[0]]], [music_vectors[i] for i in keys_using]), dtype=torch.float32).squeeze()\n","    return user_emotion_sim, music_emotion_sim, audio_features_sim\n","\n","def train_and_recommend(user_dataset, keys_using, music_emotion, music_vectors):\n","    model = ScoringModel()\n","    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n","    user_dataset_train, user_dataset_valid = split_users_into_train_test(user_dataset['liked'])\n","\n","    for epoch in range(20):\n","        print(f'Epoch {epoch}')\n","        total_train_loss = 0\n","        total_train_hits = 0\n","        total_train_data = 0\n","\n","        for user, user_data in user_dataset_train.items():\n","            train_data = user_data[:int(len(user_data) * 0.7)]\n","            test_data = user_data[int(len(user_data) * 0.7):]\n","            if len(train_data) == 0 or len(test_data) == 0:\n","              continue\n","            optimizer.zero_grad()\n","\n","\n","            for song, rating, emotion in test_data:\n","              # min은 요소가 하나여도 default 값 반환\n","                total_train_data+=1\n","                likes = min(train_data, key=lambda x: abs(x[2] - emotion), default=train_data[0])\n","                user_emotion_sim, music_emotion_sim, audio_features_sim = calculate_similarity(emotion, likes, keys_using, music_emotion, music_vectors)\n","                sorted_songs_with_scores = model(user_emotion_sim, music_emotion_sim, audio_features_sim)\n","                actual_score = next(score for song_i, score in sorted_songs_with_scores if song_i == song)\n","                loss, hit = custom_loss(sorted_songs_with_scores, actual_score,n)\n","                total_train_loss += loss.item()\n","                loss.backward()\n","                if hit:\n","                  total_train_hits+=1\n","            optimizer.step()\n","\n","        train_hit_at_n = total_train_hits / total_train_data\n","        print(f'Train HIT@n: {train_hit_at_n:.4f}, Loss: {total_train_loss:.4f}')\n","\n","        total_valid_loss = 0\n","        total_valid_hits = 0\n","        total_valid_data = 0\n","\n","        for user, user_data in user_dataset_valid.items():\n","            train_data = user_dataset_train[user]\n","            test_data = user_data\n","            if len(train_data) == 0 or len(test_data) == 0:\n","              continue\n","\n","            for song, rating, emotion in test_data:\n","                total_valid_data+=1\n","                likes = min(train_data, key=lambda x: abs(x[2] - emotion), default=train_data[0])\n","                user_emotion_sim, music_emotion_sim, audio_features_sim = calculate_similarity(emotion, likes, keys_using, music_emotion, music_vectors)\n","                sorted_songs_with_scores = model(user_emotion_sim, music_emotion_sim, audio_features_sim)\n","                actual_score = next(score for song_i, score in sorted_songs_with_scores if song_i == song)\n","                loss,hit = custom_loss(sorted_songs_with_scores, actual_score,n)\n","                total_valid_loss += loss.item()\n","                if hit:\n","                  total_valid_hits+=1\n","\n","        valid_hit_at_n  = total_valid_hits / total_valid_data\n","        print(f'Valid HIT@n: {valid_hit_at_n:.4f}, Loss: {total_valid_loss:.4f}')\n","\n","    return model\n","\n","n=16\n","model = train_and_recommend(user_dataset, keys_using, music_emotion, music_vectors)\n","print(\"Alpha, Beta, Gamma:\", model.get_weights())"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"collapsed_sections":["jXZ50Ou1lzmI"]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}